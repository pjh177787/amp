{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Perceptron import *\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "\n",
    "\n",
    "trainfile_name = './digitdata/optdigits-orig_train.txt'\n",
    "testfile_name = './digitdata/optdigits-orig_test.txt'\n",
    "\n",
    "p = Preceptron(trainfile_name, testfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit#0, epoch #0, learning_rate = 0.025, error = 41.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.075]\n",
      "Digit#0, epoch #1, learning_rate = 0.023, error = 11.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.098]\n",
      "Digit#0, epoch #2, learning_rate = 0.020, error = 6.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.098]\n",
      "Digit#0, epoch #3, learning_rate = 0.018, error = 7.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.116]\n",
      "Digit#0, epoch #4, learning_rate = 0.016, error = 5.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.132]\n",
      "Digit#0, epoch #5, learning_rate = 0.015, error = 4.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.132]\n",
      "Digit#0, epoch #6, learning_rate = 0.013, error = 2.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.132]\n",
      "Digit#0, epoch #7, learning_rate = 0.012, error = 0.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.132]\n",
      "Digit#1, epoch #0, learning_rate = 0.025, error = 123.000\n",
      "[ 0.     0.     0.    ...,  0.05   0.025 -0.225]\n",
      "Digit#1, epoch #1, learning_rate = 0.023, error = 60.000\n",
      "[ 0.     0.     0.    ...,  0.05   0.025 -0.36 ]\n",
      "Digit#1, epoch #2, learning_rate = 0.020, error = 57.000\n",
      "[ 0.     0.     0.    ...,  0.05   0.025 -0.421]\n",
      "Digit#1, epoch #3, learning_rate = 0.018, error = 45.000\n",
      "[ 0.     0.     0.    ...,  0.05   0.025 -0.475]\n",
      "Digit#1, epoch #4, learning_rate = 0.016, error = 32.000\n",
      "[ 0.     0.     0.    ...,  0.05   0.025 -0.508]\n",
      "Digit#1, epoch #5, learning_rate = 0.015, error = 29.000\n",
      "[ 0.     0.     0.    ...,  0.05   0.025 -0.553]\n",
      "Digit#1, epoch #6, learning_rate = 0.013, error = 23.000\n",
      "[ 0.     0.     0.    ...,  0.05   0.025 -0.566]\n",
      "Digit#1, epoch #7, learning_rate = 0.012, error = 16.000\n",
      "[ 0.     0.     0.    ...,  0.05   0.025 -0.566]\n",
      "Digit#1, epoch #8, learning_rate = 0.011, error = 19.000\n",
      "[ 0.     0.     0.    ...,  0.061  0.036 -0.577]\n",
      "Digit#1, epoch #9, learning_rate = 0.010, error = 15.000\n",
      "[ 0.     0.     0.    ...,  0.061  0.036 -0.586]\n",
      "Digit#1, epoch #10, learning_rate = 0.009, error = 13.000\n",
      "[ 0.     0.     0.    ...,  0.061  0.036 -0.595]\n",
      "Digit#1, epoch #11, learning_rate = 0.008, error = 12.000\n",
      "[ 0.     0.     0.    ...,  0.061  0.036 -0.595]\n",
      "Digit#1, epoch #12, learning_rate = 0.007, error = 11.000\n",
      "[ 0.     0.     0.    ...,  0.061  0.036 -0.602]\n",
      "Digit#1, epoch #13, learning_rate = 0.006, error = 7.000\n",
      "[ 0.     0.     0.    ...,  0.061  0.036 -0.608]\n",
      "Digit#1, epoch #14, learning_rate = 0.006, error = 6.000\n",
      "[ 0.     0.     0.    ...,  0.061  0.036 -0.608]\n",
      "Digit#1, epoch #15, learning_rate = 0.005, error = 12.000\n",
      "[ 0.     0.     0.    ...,  0.061  0.036 -0.608]\n",
      "Digit#1, epoch #16, learning_rate = 0.005, error = 9.000\n",
      "[ 0.     0.     0.    ...,  0.061  0.036 -0.613]\n",
      "Digit#1, epoch #17, learning_rate = 0.004, error = 5.000\n",
      "[ 0.     0.     0.    ...,  0.061  0.036 -0.617]\n",
      "Digit#1, epoch #18, learning_rate = 0.004, error = 4.000\n",
      "[ 0.     0.     0.    ...,  0.061  0.036 -0.617]\n",
      "Digit#1, epoch #19, learning_rate = 0.003, error = 4.000\n",
      "[ 0.     0.     0.    ...,  0.061  0.036 -0.617]\n",
      "Digit#2, epoch #0, learning_rate = 0.025, error = 64.000\n",
      "[ 0.     0.     0.    ...,  0.025  0.025 -0.1  ]\n",
      "Digit#2, epoch #1, learning_rate = 0.023, error = 20.000\n",
      "[ 0.     0.     0.    ...,  0.025  0.025 -0.1  ]\n",
      "Digit#2, epoch #2, learning_rate = 0.020, error = 9.000\n",
      "[ 0.     0.     0.    ...,  0.045  0.045 -0.12 ]\n",
      "Digit#2, epoch #3, learning_rate = 0.018, error = 9.000\n",
      "[ 0.     0.     0.    ...,  0.045  0.045 -0.102]\n",
      "Digit#2, epoch #4, learning_rate = 0.016, error = 9.000\n",
      "[ 0.     0.     0.    ...,  0.062  0.062 -0.118]\n",
      "Digit#2, epoch #5, learning_rate = 0.015, error = 7.000\n",
      "[ 0.     0.     0.    ...,  0.062  0.062 -0.104]\n",
      "Digit#2, epoch #6, learning_rate = 0.013, error = 5.000\n",
      "[ 0.     0.     0.    ...,  0.075  0.075 -0.117]\n",
      "Digit#2, epoch #7, learning_rate = 0.012, error = 8.000\n",
      "[ 0.     0.     0.    ...,  0.075  0.075 -0.117]\n",
      "Digit#2, epoch #8, learning_rate = 0.011, error = 8.000\n",
      "[ 0.     0.     0.    ...,  0.086  0.086 -0.117]\n",
      "Digit#2, epoch #9, learning_rate = 0.010, error = 2.000\n",
      "[ 0.     0.     0.    ...,  0.086  0.086 -0.117]\n",
      "Digit#2, epoch #10, learning_rate = 0.009, error = 2.000\n",
      "[ 0.     0.     0.    ...,  0.086  0.086 -0.117]\n",
      "Digit#2, epoch #11, learning_rate = 0.008, error = 2.000\n",
      "[ 0.     0.     0.    ...,  0.086  0.086 -0.117]\n",
      "Digit#2, epoch #12, learning_rate = 0.007, error = 0.000\n",
      "[ 0.     0.     0.    ...,  0.086  0.086 -0.117]\n",
      "Digit#3, epoch #0, learning_rate = 0.025, error = 86.000\n",
      "[ 0.   0.   0.  ...,  0.   0.  -0.1]\n",
      "Digit#3, epoch #1, learning_rate = 0.023, error = 39.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.123]\n",
      "Digit#3, epoch #2, learning_rate = 0.020, error = 22.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.123]\n",
      "Digit#3, epoch #3, learning_rate = 0.018, error = 19.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.141]\n",
      "Digit#3, epoch #4, learning_rate = 0.016, error = 15.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.157]\n",
      "Digit#3, epoch #5, learning_rate = 0.015, error = 11.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.142]\n",
      "Digit#3, epoch #6, learning_rate = 0.013, error = 15.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.156]\n",
      "Digit#3, epoch #7, learning_rate = 0.012, error = 8.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.156]\n",
      "Digit#3, epoch #8, learning_rate = 0.011, error = 6.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.156]\n",
      "Digit#3, epoch #9, learning_rate = 0.010, error = 5.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.165]\n",
      "Digit#3, epoch #10, learning_rate = 0.009, error = 6.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.165]\n",
      "Digit#3, epoch #11, learning_rate = 0.008, error = 2.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.165]\n",
      "Digit#3, epoch #12, learning_rate = 0.007, error = 2.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.165]\n",
      "Digit#3, epoch #13, learning_rate = 0.006, error = 1.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.172]\n",
      "Digit#3, epoch #14, learning_rate = 0.006, error = 2.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.172]\n",
      "Digit#3, epoch #15, learning_rate = 0.005, error = 1.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.167]\n",
      "Digit#3, epoch #16, learning_rate = 0.005, error = 0.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.167]\n",
      "Digit#4, epoch #0, learning_rate = 0.025, error = 73.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.025]\n",
      "Digit#4, epoch #1, learning_rate = 0.023, error = 26.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.025]\n",
      "Digit#4, epoch #2, learning_rate = 0.020, error = 19.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.005]\n",
      "Digit#4, epoch #3, learning_rate = 0.018, error = 12.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.005]\n",
      "Digit#4, epoch #4, learning_rate = 0.016, error = 12.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.005]\n",
      "Digit#4, epoch #5, learning_rate = 0.015, error = 9.000\n",
      "[ 0.    0.    0.   ...,  0.    0.    0.01]\n",
      "Digit#4, epoch #6, learning_rate = 0.013, error = 4.000\n",
      "[ 0.    0.    0.   ...,  0.    0.    0.01]\n",
      "Digit#4, epoch #7, learning_rate = 0.012, error = 0.000\n",
      "[ 0.    0.    0.   ...,  0.    0.    0.01]\n",
      "Digit#5, epoch #0, learning_rate = 0.025, error = 89.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.075]\n",
      "Digit#5, epoch #1, learning_rate = 0.023, error = 32.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.075]\n",
      "Digit#5, epoch #2, learning_rate = 0.020, error = 24.000\n",
      "[ 0.     0.     0.    ..., -0.02   0.    -0.075]\n",
      "Digit#5, epoch #3, learning_rate = 0.018, error = 16.000\n",
      "[ 0.     0.     0.    ..., -0.02   0.    -0.075]\n",
      "Digit#5, epoch #4, learning_rate = 0.016, error = 15.000\n",
      "[ 0.     0.     0.    ..., -0.02   0.    -0.091]\n",
      "Digit#5, epoch #5, learning_rate = 0.015, error = 6.000\n",
      "[ 0.     0.     0.    ..., -0.02   0.    -0.091]\n",
      "Digit#5, epoch #6, learning_rate = 0.013, error = 2.000\n",
      "[ 0.     0.     0.    ..., -0.02   0.    -0.091]\n",
      "Digit#5, epoch #7, learning_rate = 0.012, error = 2.000\n",
      "[ 0.     0.     0.    ..., -0.02   0.    -0.091]\n",
      "Digit#5, epoch #8, learning_rate = 0.011, error = 0.000\n",
      "[ 0.     0.     0.    ..., -0.02   0.    -0.091]\n",
      "Digit#6, epoch #0, learning_rate = 0.025, error = 51.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.075]\n",
      "Digit#6, epoch #1, learning_rate = 0.023, error = 13.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.098]\n",
      "Digit#6, epoch #2, learning_rate = 0.020, error = 7.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit#6, epoch #3, learning_rate = 0.018, error = 9.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.095]\n",
      "Digit#6, epoch #4, learning_rate = 0.016, error = 2.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.095]\n",
      "Digit#6, epoch #5, learning_rate = 0.015, error = 4.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.095]\n",
      "Digit#6, epoch #6, learning_rate = 0.013, error = 2.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.095]\n",
      "Digit#6, epoch #7, learning_rate = 0.012, error = 4.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.095]\n",
      "Digit#6, epoch #8, learning_rate = 0.011, error = 1.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.085]\n",
      "Digit#6, epoch #9, learning_rate = 0.010, error = 4.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.085]\n",
      "Digit#6, epoch #10, learning_rate = 0.009, error = 1.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.093]\n",
      "Digit#6, epoch #11, learning_rate = 0.008, error = 0.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.093]\n",
      "Digit#7, epoch #0, learning_rate = 0.025, error = 42.000\n",
      "[ 0.    0.    0.   ...,  0.    0.   -0.05]\n",
      "Digit#7, epoch #1, learning_rate = 0.023, error = 14.000\n",
      "[ 0.    0.    0.   ...,  0.    0.   -0.05]\n",
      "Digit#7, epoch #2, learning_rate = 0.020, error = 7.000\n",
      "[ 0.    0.    0.   ...,  0.    0.   -0.07]\n",
      "Digit#7, epoch #3, learning_rate = 0.018, error = 6.000\n",
      "[ 0.    0.    0.   ...,  0.    0.   -0.07]\n",
      "Digit#7, epoch #4, learning_rate = 0.016, error = 6.000\n",
      "[ 0.    0.    0.   ...,  0.    0.   -0.07]\n",
      "Digit#7, epoch #5, learning_rate = 0.015, error = 3.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.085]\n",
      "Digit#7, epoch #6, learning_rate = 0.013, error = 2.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.085]\n",
      "Digit#7, epoch #7, learning_rate = 0.012, error = 2.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.085]\n",
      "Digit#7, epoch #8, learning_rate = 0.011, error = 0.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.085]\n",
      "Digit#8, epoch #0, learning_rate = 0.025, error = 159.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.325]\n",
      "Digit#8, epoch #1, learning_rate = 0.023, error = 90.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.415]\n",
      "Digit#8, epoch #2, learning_rate = 0.020, error = 70.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.456]\n",
      "Digit#8, epoch #3, learning_rate = 0.018, error = 58.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.492]\n",
      "Digit#8, epoch #4, learning_rate = 0.016, error = 55.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.541]\n",
      "Digit#8, epoch #5, learning_rate = 0.015, error = 50.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.571]\n",
      "Digit#8, epoch #6, learning_rate = 0.013, error = 37.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.584]\n",
      "Digit#8, epoch #7, learning_rate = 0.012, error = 40.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.608]\n",
      "Digit#8, epoch #8, learning_rate = 0.011, error = 23.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.619]\n",
      "Digit#8, epoch #9, learning_rate = 0.010, error = 22.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.619]\n",
      "Digit#8, epoch #10, learning_rate = 0.009, error = 17.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.627]\n",
      "Digit#8, epoch #11, learning_rate = 0.008, error = 24.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.627]\n",
      "Digit#8, epoch #12, learning_rate = 0.007, error = 21.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.634]\n",
      "Digit#8, epoch #13, learning_rate = 0.006, error = 17.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.641]\n",
      "Digit#8, epoch #14, learning_rate = 0.006, error = 15.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.646]\n",
      "Digit#8, epoch #15, learning_rate = 0.005, error = 14.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.646]\n",
      "Digit#8, epoch #16, learning_rate = 0.005, error = 11.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.651]\n",
      "Digit#8, epoch #17, learning_rate = 0.004, error = 8.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.651]\n",
      "Digit#8, epoch #18, learning_rate = 0.004, error = 5.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.647]\n",
      "Digit#8, epoch #19, learning_rate = 0.003, error = 7.000\n",
      "[ 0.     0.     0.    ...,  0.     0.    -0.651]\n",
      "Digit#9, epoch #0, learning_rate = 0.025, error = 156.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.15 ]\n",
      "Digit#9, epoch #1, learning_rate = 0.023, error = 101.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.262]\n",
      "Digit#9, epoch #2, learning_rate = 0.020, error = 71.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.323]\n",
      "Digit#9, epoch #3, learning_rate = 0.018, error = 56.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.36 ]\n",
      "Digit#9, epoch #4, learning_rate = 0.016, error = 44.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.393]\n",
      "Digit#9, epoch #5, learning_rate = 0.015, error = 47.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.437]\n",
      "Digit#9, epoch #6, learning_rate = 0.013, error = 42.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.463]\n",
      "Digit#9, epoch #7, learning_rate = 0.012, error = 33.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.475]\n",
      "Digit#9, epoch #8, learning_rate = 0.011, error = 19.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.486]\n",
      "Digit#9, epoch #9, learning_rate = 0.010, error = 25.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.496]\n",
      "Digit#9, epoch #10, learning_rate = 0.009, error = 18.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.513]\n",
      "Digit#9, epoch #11, learning_rate = 0.008, error = 15.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.521]\n",
      "Digit#9, epoch #12, learning_rate = 0.007, error = 11.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.514]\n",
      "Digit#9, epoch #13, learning_rate = 0.006, error = 13.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.52 ]\n",
      "Digit#9, epoch #14, learning_rate = 0.006, error = 5.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.515]\n",
      "Digit#9, epoch #15, learning_rate = 0.005, error = 5.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.52 ]\n",
      "Digit#9, epoch #16, learning_rate = 0.005, error = 2.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.52 ]\n",
      "Digit#9, epoch #17, learning_rate = 0.004, error = 4.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.52 ]\n",
      "Digit#9, epoch #18, learning_rate = 0.004, error = 6.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.52 ]\n",
      "Digit#9, epoch #19, learning_rate = 0.003, error = 2.000\n",
      "[ 0.     0.     0.    ..., -0.025 -0.025 -0.52 ]\n"
     ]
    }
   ],
   "source": [
    "p.perceptron_train(0.025, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each digit, show the test examples from that class that have the highest and lowest posterior probabilities according to your classifier.\n",
      "[[9.9735069749999905, 3894], [7.4777424226997589, 12276], [12.494710105523495, 9075], [10.093374832624434, 10329], [10.280494800000003, 3960], [13.117202339999997, 11253], [9.8677862206350024, 3432], [9.548775880000008, 7656], [13.328602488941339, 8250], [9.7015982799056317, 13365]]\n",
      "\n",
      "\n",
      "[[-23.576613935666078, 12342], [-27.980813890000015, 14553], [-26.978949199999992, 5610], [-25.374789475, 13926], [-27.394579435000011, 2409], [-21.705113341467516, 14289], [-22.372903685000011, 3630], [-24.992283632127677, 9735], [-20.637822918012212, 12144], [-27.602891649065, 13068]]\n",
      "Classification Rate For Each Digit:\n",
      "0 1.0\n",
      "1 0.9777777777777777\n",
      "2 0.8780487804878049\n",
      "3 0.9696969696969697\n",
      "4 0.9152542372881356\n",
      "5 1.0\n",
      "6 0.9534883720930233\n",
      "7 0.9787234042553191\n",
      "8 0.95\n",
      "9 0.9047619047619048\n",
      "Confusion Matrix:\n",
      "[ 0.081  0.     0.     0.     0.     0.     0.     0.     0.     0.   ]\n",
      "[ 0.     0.099  0.     0.     0.002  0.     0.     0.     0.     0.   ]\n",
      "[ 0.     0.     0.081  0.     0.     0.     0.     0.     0.     0.005]\n",
      "[ 0.     0.     0.     0.072  0.002  0.     0.     0.     0.     0.002]\n",
      "[ 0.     0.     0.     0.     0.122  0.     0.002  0.002  0.     0.   ]\n",
      "[ 0.     0.     0.     0.     0.     0.131  0.     0.     0.002  0.   ]\n",
      "[ 0.     0.     0.     0.     0.     0.     0.092  0.     0.     0.   ]\n",
      "[ 0.     0.002  0.     0.     0.     0.     0.     0.104  0.     0.   ]\n",
      "[ 0.     0.     0.009  0.     0.005  0.     0.002  0.     0.086  0.002]\n",
      "[ 0.     0.     0.002  0.002  0.002  0.     0.     0.     0.002  0.086]\n",
      "[8, 2, 7, 4, 4, 6, 2, 9, 2, 5, 6, 6, 6, 7, 9, 5, 4, 4, 7, 1, 3, 7, 3, 8, 5, 8, 5, 2, 6, 4, 5, 2, 3, 7, 4, 2, 7, 5, 2, 8, 1, 1, 2, 2, 3, 4, 4, 1, 1, 0, 6, 9, 8, 3, 3, 9, 2, 4, 5, 4, 6, 4, 9, 3, 0, 4, 0, 7, 1, 5, 1, 2, 2, 4, 4, 8, 9, 2, 6, 8, 1, 6, 7, 6, 3, 9, 8, 4, 8, 5, 9, 9, 7, 8, 5, 2, 5, 0, 0, 9, 6, 7, 9, 0, 6, 6, 1, 3, 1, 2, 6, 7, 4, 6, 8, 5, 9, 4, 0, 7, 4, 7, 3, 7, 9, 5, 7, 8, 1, 7, 1, 7, 8, 2, 8, 6, 5, 4, 1, 7, 8, 1, 3, 4, 0, 4, 6, 7, 8, 9, 9, 5, 6, 1, 6, 5, 1, 5, 4, 9, 0, 8, 0, 5, 1, 5, 4, 8, 9, 9, 2, 0, 1, 0, 4, 1, 0, 0, 8, 2, 9, 5, 6, 4, 3, 7, 6, 5, 8, 1, 7, 0, 6, 1, 4, 3, 5, 5, 0, 5, 1, 8, 4, 8, 9, 9, 0, 6, 9, 1, 7, 7, 0, 4, 4, 0, 0, 6, 1, 8, 5, 4, 2, 7, 3, 3, 4, 1, 5, 8, 1, 5, 7, 5, 3, 4, 0, 1, 5, 3, 8, 4, 5, 9, 5, 4, 9, 8, 5, 3, 8, 4, 9, 2, 3, 8, 1, 4, 6, 4, 8, 4, 5, 8, 4, 5, 2, 1, 1, 2, 0, 0, 5, 5, 5, 2, 5, 8, 4, 7, 9, 1, 5, 2, 3, 3, 1, 7, 0, 9, 9, 7, 0, 4, 0, 7, 7, 2, 8, 0, 6, 7, 6, 2, 6, 6, 6, 2, 9, 2, 5, 2, 1, 3, 9, 1, 7, 8, 8, 5, 8, 4, 2, 5, 4, 9, 0, 3, 4, 8, 8, 3, 1, 7, 7, 8, 4, 5, 5, 5, 9, 5, 8, 7, 4, 7, 7, 6, 4, 1, 6, 7, 3, 6, 7, 9, 1, 2, 7, 2, 1, 7, 6, 5, 0, 4, 1, 8, 8, 5, 5, 8, 1, 7, 0, 2, 5, 7, 4, 9, 9, 3, 9, 3, 6, 6, 2, 0, 1, 0, 0, 4, 5, 5, 5, 0, 9, 7, 2, 2, 7, 4, 6, 5, 3, 9, 4, 0, 3, 9, 2, 1, 2, 4, 0, 6, 5, 4, 3, 6, 3, 6, 3, 9, 8, 3, 8, 7, 1, 7, 9, 9, 5, 5, 8, 1, 4, 5, 4, 8, 3, 1, 6, 5]\n",
      "0.9527027027027027\n"
     ]
    }
   ],
   "source": [
    "p.perceptron_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 1]\n",
      "4589474696 4589464264\n"
     ]
    }
   ],
   "source": [
    "x = [1, 2, 3]\n",
    "y = x + [1]\n",
    "print(y)\n",
    "print(id(x), id(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.     0.     0.    ..., -3.606 -1.803  0.   ]\n",
      "[ 0.     0.     0.    ..., -0.601 -0.601  0.   ]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "epoch #0, learning_rate = 0.001, error = 2436.000\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.     0.     0.    ..., -3.612 -1.806  0.   ]\n",
      "[ 0.     0.     0.    ..., -0.602 -0.602  0.   ]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "epoch #1, learning_rate = 0.001, error = 2436.000\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.     0.     0.    ..., -3.618 -1.809  0.   ]\n",
      "[ 0.     0.     0.    ..., -0.603 -0.603  0.   ]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "epoch #2, learning_rate = 0.001, error = 2436.000\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.     0.     0.    ..., -3.624 -1.812  0.   ]\n",
      "[ 0.     0.     0.    ..., -0.604 -0.604  0.   ]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "epoch #3, learning_rate = 0.001, error = 2436.000\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.     0.     0.    ..., -3.63  -1.815  0.   ]\n",
      "[ 0.     0.     0.    ..., -0.605 -0.605  0.   ]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "epoch #4, learning_rate = 0.001, error = 2436.000\n"
     ]
    }
   ],
   "source": [
    "p.perceptron_training(0.001, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(p.weight_list)):\n",
    "    print(p.weight_list[i])\n",
    "\n",
    "bias_en = True\n",
    "predictions = []\n",
    "correct_counts = [0 for i in range(10)]\n",
    "total_counts = [0 for i in range(10)]\n",
    "correct = 0\n",
    "each = 0\n",
    "line = 0\n",
    "largest_posterior = [[float('-inf'), \" \"] for i in range(10)]\n",
    "smallest_posterior = [[float('inf'), \" \"] for i in range(10)]\n",
    "\n",
    "if bias_en:\n",
    "    bias = [1]\n",
    "else:\n",
    "    bias = [0]\n",
    "    \n",
    "for idx in range(len(p.testing_labels)):\n",
    "    maxi = float('-inf')\n",
    "    mini = float('inf')\n",
    "    predicted = 0\n",
    "    label = p.testing_labels[idx]\n",
    "    \n",
    "    candidates = []\n",
    "    for each_possibility in range(10):\n",
    "        row = p.testing_classes[idx] + bias\n",
    "        actuation, possibility = p.predict(row, p.weight_list[each_possibility])\n",
    "        if possibility > maxi:\n",
    "            predicted = each_possibility\n",
    "            maxi = possibility\n",
    "        if possibility < mini:\n",
    "            mini = possibility\n",
    "        if actuation == 1:\n",
    "            candidates.append((each_possibility, possibility))\n",
    "    print(candidates)\n",
    "    \n",
    "    predictions.append(predicted)\n",
    "    if maxi > largest_posterior[label][0]:\n",
    "        largest_posterior[label][0] = maxi\n",
    "        largest_posterior[label][1] = line\n",
    "    if mini < smallest_posterior[label][0]:\n",
    "        smallest_posterior[label][0] = mini\n",
    "        smallest_posterior[label][1] = line\n",
    "\n",
    "    p.confusion_matrix[predicted][label] += 1\n",
    "\n",
    "    if label == predicted:\n",
    "        correct += 1\n",
    "        correct_counts[label] += 1\n",
    "    total_counts[label] += 1\n",
    "\n",
    "    each += 1\n",
    "    line += 33\n",
    "\n",
    "correct_prec = correct / each\n",
    "p.confusion_matrix = np.array([[num/each for num in col] for col in p.confusion_matrix])\n",
    "\n",
    "print('For each digit, show the test examples from that class that have the highest and lowest posterior probabilities according to your classifier.')\n",
    "print(largest_posterior)\n",
    "print('\\n')\n",
    "print(smallest_posterior)\n",
    "\n",
    "print('Classification Rate For Each Digit:')\n",
    "for i in range(10):\n",
    "    print(i, correct_counts[i]/total_counts[i])\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "for i in range(10):\n",
    "    print(p.confusion_matrix[i])\n",
    "\n",
    "print(predictions)\n",
    "print(correct_prec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
