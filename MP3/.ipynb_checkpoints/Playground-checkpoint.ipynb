{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Perceptron import *\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "\n",
    "\n",
    "trainfile_name = './digitdata/optdigits-orig_train.txt'\n",
    "testfile_name = './digitdata/optdigits-orig_test.txt'\n",
    "\n",
    "p = Preceptron(trainfile_name, testfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.perceptron_train(0.025, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each digit, show the test examples from that class that have the highest and lowest posterior probabilities according to your classifier.\n",
      "[[9.9735069749999905, 3894], [7.4777424226997589, 12276], [12.494710105523495, 9075], [10.093374832624434, 10329], [10.280494800000003, 3960], [13.117202339999997, 11253], [9.8677862206350024, 3432], [9.548775880000008, 7656], [13.328602488941339, 8250], [9.7015982799056317, 13365]]\n",
      "\n",
      "\n",
      "[[-23.576613935666078, 12342], [-27.980813890000015, 14553], [-26.978949199999992, 5610], [-25.374789475, 13926], [-27.394579435000011, 2409], [-21.705113341467516, 14289], [-22.372903685000011, 3630], [-24.992283632127677, 9735], [-20.637822918012212, 12144], [-27.602891649065, 13068]]\n",
      "Classification Rate For Each Digit:\n",
      "0 1.0\n",
      "1 0.9777777777777777\n",
      "2 0.8780487804878049\n",
      "3 0.9696969696969697\n",
      "4 0.9152542372881356\n",
      "5 1.0\n",
      "6 0.9534883720930233\n",
      "7 0.9787234042553191\n",
      "8 0.95\n",
      "9 0.9047619047619048\n",
      "Confusion Matrix:\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.     0.978  0.     0.     0.017  0.     0.     0.     0.     0.   ]\n",
      "[ 0.     0.     0.878  0.     0.     0.     0.     0.     0.     0.048]\n",
      "[ 0.     0.     0.     0.97   0.017  0.     0.     0.     0.     0.024]\n",
      "[ 0.     0.     0.     0.     0.915  0.     0.023  0.021  0.     0.   ]\n",
      "[ 0.     0.     0.     0.     0.     1.     0.     0.     0.025  0.   ]\n",
      "[ 0.     0.     0.     0.     0.     0.     0.953  0.     0.     0.   ]\n",
      "[ 0.     0.022  0.     0.     0.     0.     0.     0.979  0.     0.   ]\n",
      "[ 0.     0.     0.098  0.     0.034  0.     0.023  0.     0.95   0.024]\n",
      "[ 0.     0.     0.024  0.03   0.017  0.     0.     0.     0.025  0.905]\n",
      "[8, 2, 7, 4, 4, 6, 2, 9, 2, 5, 6, 6, 6, 7, 9, 5, 4, 4, 7, 1, 3, 7, 3, 8, 5, 8, 5, 2, 6, 4, 5, 2, 3, 7, 4, 2, 7, 5, 2, 8, 1, 1, 2, 2, 3, 4, 4, 1, 1, 0, 6, 9, 8, 3, 3, 9, 2, 4, 5, 4, 6, 4, 9, 3, 0, 4, 0, 7, 1, 5, 1, 2, 2, 4, 4, 8, 9, 2, 6, 8, 1, 6, 7, 6, 3, 9, 8, 4, 8, 5, 9, 9, 7, 8, 5, 2, 5, 0, 0, 9, 6, 7, 9, 0, 6, 6, 1, 3, 1, 2, 6, 7, 4, 6, 8, 5, 9, 4, 0, 7, 4, 7, 3, 7, 9, 5, 7, 8, 1, 7, 1, 7, 8, 2, 8, 6, 5, 4, 1, 7, 8, 1, 3, 4, 0, 4, 6, 7, 8, 9, 9, 5, 6, 1, 6, 5, 1, 5, 4, 9, 0, 8, 0, 5, 1, 5, 4, 8, 9, 9, 2, 0, 1, 0, 4, 1, 0, 0, 8, 2, 9, 5, 6, 4, 3, 7, 6, 5, 8, 1, 7, 0, 6, 1, 4, 3, 5, 5, 0, 5, 1, 8, 4, 8, 9, 9, 0, 6, 9, 1, 7, 7, 0, 4, 4, 0, 0, 6, 1, 8, 5, 4, 2, 7, 3, 3, 4, 1, 5, 8, 1, 5, 7, 5, 3, 4, 0, 1, 5, 3, 8, 4, 5, 9, 5, 4, 9, 8, 5, 3, 8, 4, 9, 2, 3, 8, 1, 4, 6, 4, 8, 4, 5, 8, 4, 5, 2, 1, 1, 2, 0, 0, 5, 5, 5, 2, 5, 8, 4, 7, 9, 1, 5, 2, 3, 3, 1, 7, 0, 9, 9, 7, 0, 4, 0, 7, 7, 2, 8, 0, 6, 7, 6, 2, 6, 6, 6, 2, 9, 2, 5, 2, 1, 3, 9, 1, 7, 8, 8, 5, 8, 4, 2, 5, 4, 9, 0, 3, 4, 8, 8, 3, 1, 7, 7, 8, 4, 5, 5, 5, 9, 5, 8, 7, 4, 7, 7, 6, 4, 1, 6, 7, 3, 6, 7, 9, 1, 2, 7, 2, 1, 7, 6, 5, 0, 4, 1, 8, 8, 5, 5, 8, 1, 7, 0, 2, 5, 7, 4, 9, 9, 3, 9, 3, 6, 6, 2, 0, 1, 0, 0, 4, 5, 5, 5, 0, 9, 7, 2, 2, 7, 4, 6, 5, 3, 9, 4, 0, 3, 9, 2, 1, 2, 4, 0, 6, 5, 4, 3, 6, 3, 6, 3, 9, 8, 3, 8, 7, 1, 7, 9, 9, 5, 5, 8, 1, 4, 5, 4, 8, 3, 1, 6, 5]\n",
      "0.9527027027027027\n"
     ]
    }
   ],
   "source": [
    "p.perceptron_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 1]\n",
      "4589474696 4589464264\n"
     ]
    }
   ],
   "source": [
    "x = [1, 2, 3]\n",
    "y = x + [1]\n",
    "print(y)\n",
    "print(id(x), id(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.     0.     0.    ..., -3.606 -1.803  0.   ]\n",
      "[ 0.     0.     0.    ..., -0.601 -0.601  0.   ]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "epoch #0, learning_rate = 0.001, error = 2436.000\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.     0.     0.    ..., -3.612 -1.806  0.   ]\n",
      "[ 0.     0.     0.    ..., -0.602 -0.602  0.   ]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "epoch #1, learning_rate = 0.001, error = 2436.000\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.     0.     0.    ..., -3.618 -1.809  0.   ]\n",
      "[ 0.     0.     0.    ..., -0.603 -0.603  0.   ]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "epoch #2, learning_rate = 0.001, error = 2436.000\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.     0.     0.    ..., -3.624 -1.812  0.   ]\n",
      "[ 0.     0.     0.    ..., -0.604 -0.604  0.   ]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "epoch #3, learning_rate = 0.001, error = 2436.000\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.     0.     0.    ..., -3.63  -1.815  0.   ]\n",
      "[ 0.     0.     0.    ..., -0.605 -0.605  0.   ]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "epoch #4, learning_rate = 0.001, error = 2436.000\n"
     ]
    }
   ],
   "source": [
    "p.perceptron_training(0.001, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(p.weight_list)):\n",
    "    print(p.weight_list[i])\n",
    "\n",
    "bias_en = True\n",
    "predictions = []\n",
    "correct_counts = [0 for i in range(10)]\n",
    "total_counts = [0 for i in range(10)]\n",
    "correct = 0\n",
    "each = 0\n",
    "line = 0\n",
    "largest_posterior = [[float('-inf'), \" \"] for i in range(10)]\n",
    "smallest_posterior = [[float('inf'), \" \"] for i in range(10)]\n",
    "\n",
    "if bias_en:\n",
    "    bias = [1]\n",
    "else:\n",
    "    bias = [0]\n",
    "    \n",
    "for idx in range(len(p.testing_labels)):\n",
    "    maxi = float('-inf')\n",
    "    mini = float('inf')\n",
    "    predicted = 0\n",
    "    label = p.testing_labels[idx]\n",
    "    \n",
    "    candidates = []\n",
    "    for each_possibility in range(10):\n",
    "        row = p.testing_classes[idx] + bias\n",
    "        actuation, possibility = p.predict(row, p.weight_list[each_possibility])\n",
    "        if possibility > maxi:\n",
    "            predicted = each_possibility\n",
    "            maxi = possibility\n",
    "        if possibility < mini:\n",
    "            mini = possibility\n",
    "        if actuation == 1:\n",
    "            candidates.append((each_possibility, possibility))\n",
    "    print(candidates)\n",
    "    \n",
    "    predictions.append(predicted)\n",
    "    if maxi > largest_posterior[label][0]:\n",
    "        largest_posterior[label][0] = maxi\n",
    "        largest_posterior[label][1] = line\n",
    "    if mini < smallest_posterior[label][0]:\n",
    "        smallest_posterior[label][0] = mini\n",
    "        smallest_posterior[label][1] = line\n",
    "\n",
    "    p.confusion_matrix[predicted][label] += 1\n",
    "\n",
    "    if label == predicted:\n",
    "        correct += 1\n",
    "        correct_counts[label] += 1\n",
    "    total_counts[label] += 1\n",
    "\n",
    "    each += 1\n",
    "    line += 33\n",
    "\n",
    "correct_prec = correct / each\n",
    "p.confusion_matrix = np.array([[num/each for num in col] for col in p.confusion_matrix])\n",
    "\n",
    "print('For each digit, show the test examples from that class that have the highest and lowest posterior probabilities according to your classifier.')\n",
    "print(largest_posterior)\n",
    "print('\\n')\n",
    "print(smallest_posterior)\n",
    "\n",
    "print('Classification Rate For Each Digit:')\n",
    "for i in range(10):\n",
    "    print(i, correct_counts[i]/total_counts[i])\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "for i in range(10):\n",
    "    print(p.confusion_matrix[i])\n",
    "\n",
    "print(predictions)\n",
    "print(correct_prec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
